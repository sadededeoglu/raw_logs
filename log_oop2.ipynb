{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae49ad68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Logger funnel_pipeline (INFO)>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from typing import Optional, Dict\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "from pydantic import BaseModel, field_validator\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s %(message)s')\n",
    "logger = logging.getLogger(\"funnel_pipeline\")\n",
    "logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5b590f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------- Reader ---------------------------\n",
    "class DataReader:\n",
    "    def read(self) -> pd.DataFrame:\n",
    "        raise NotImplementedError\n",
    "\n",
    "class ParquetReader(DataReader):\n",
    "    def __init__(self, file_path: str):\n",
    "        self.file_path = Path(file_path)\n",
    "\n",
    "    def read(self) -> pd.DataFrame:\n",
    "        path_str = str(self.file_path)\n",
    "        logger.info(f\"Reading parquet from: {path_str}\")\n",
    "\n",
    "        #dosya okuma\n",
    "        try:\n",
    "            df = pd.read_parquet(path_str)\n",
    "        except Exception as e:\n",
    "            logger.exception(\"Failed to read parquet with pandas.read_parquet, attempting pyarrow.Dataset\")    \n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85c767cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------- Models ---------------------------\n",
    "class UserModel(BaseModel):\n",
    "    user_id: Optional[int]\n",
    "    subscriber_id: Optional[int]\n",
    "    country: Optional[str]\n",
    "    has_email_contact_permission: Optional[bool]\n",
    "    has_phone_contact_permission: Optional[bool]\n",
    "\n",
    "    @field_validator(\"has_email_contact_permission\", \"has_phone_contact_permission\", mode=\"before\")\n",
    "    def to_bool(cls, v):\n",
    "        if v is None:\n",
    "            return None\n",
    "        if isinstance(v, str):\n",
    "            return v.lower() in [\"yes\", \"true\", \"1\", \"y\"]\n",
    "        return bool(v)\n",
    "\n",
    "class SessionModel(BaseModel):\n",
    "    session_id: str\n",
    "    user_id: Optional[int]\n",
    "    user_agent: Optional[str]\n",
    "    device_type: Optional[str]\n",
    "    ip_address: Optional[str]\n",
    "    utm_source: Optional[str]\n",
    "\n",
    "class EventModel(BaseModel):\n",
    "    request_id: str\n",
    "    session_id: str\n",
    "    funnel_id: Optional[str]\n",
    "    timestamp: datetime\n",
    "    page_name: Optional[str]\n",
    "    search_query: Optional[str]\n",
    "    destination_id: Optional[int]\n",
    "    num_guests: Optional[int]\n",
    "    updated_at: Optional[datetime] = None\n",
    "\n",
    "    @field_validator('timestamp', mode='before')\n",
    "    def parse_ts(cls, v):\n",
    "        if v is None:\n",
    "            raise ValueError('timestamp is required')\n",
    "        if isinstance(v, str):\n",
    "            return datetime.fromisoformat(v)\n",
    "        if isinstance(v, (int, float)):\n",
    "            # assume epoch\n",
    "            return datetime.fromtimestamp(v)\n",
    "        return v\n",
    "\n",
    "class HotelModel(BaseModel):\n",
    "    hotel_id: int\n",
    "    hotel_price: Optional[float]\n",
    "    currency: Optional[str]\n",
    "\n",
    "    @field_validator(\"hotel_price\", mode=\"before\")\n",
    "    def clean_price(cls, v):\n",
    "        if v is None:\n",
    "            return None\n",
    "        if isinstance(v, str):\n",
    "            v = v.replace(\",\", \".\").replace(\"$\", \"\").strip()\n",
    "        try:\n",
    "            return float(v)\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "class PaymentModel(BaseModel):\n",
    "    request_id: str\n",
    "    payment_status: Optional[str]\n",
    "    confirmation_number: Optional[str]\n",
    "\n",
    "    @field_validator(\"payment_status\", mode=\"before\")\n",
    "    def normalize_status(cls, v):\n",
    "        if v is None:\n",
    "            return None\n",
    "        v = v.strip().lower()\n",
    "        mapping = {\"success\": \"completed\", \"done\": \"completed\", \"ok\": \"completed\", \"paid\": \"completed\", \"fail\": \"failed\", \"error\": \"failed\"}\n",
    "        return mapping.get(v, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5021e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------- Processor ---------------------------\n",
    "class FunnelProcessor:\n",
    "    def validate_and_normalize(self, df: pd.DataFrame) -> Dict[str, pd.DataFrame]:\n",
    "        users, sessions, events, hotels, payments = [], [], [], [], []\n",
    "        records = df.to_dict(orient='records')\n",
    "        for i, row in enumerate(records):\n",
    "            try:\n",
    "                # For models that require fields, guard with try except per model so one bad model doesn't drop all\n",
    "                try:\n",
    "                    u = UserModel(**row).model_dump(exclude_none=True)\n",
    "                    u and users.append(u)\n",
    "                except Exception as e:\n",
    "                    logger.debug(f\"UserModel validation failed for row {i}: {e}\")\n",
    "\n",
    "                try:\n",
    "                    s = SessionModel(**row).model_dump(exclude_none=True)\n",
    "                    s and sessions.append(s)\n",
    "                except Exception as e:\n",
    "                    logger.debug(f\"SessionModel validation failed for row {i}: {e}\")\n",
    "\n",
    "                try:\n",
    "                    ev = EventModel(**row).model_dump(exclude_none=True)\n",
    "                    ev and events.append(ev)\n",
    "                except Exception as e:\n",
    "                    logger.warning(f\"EventModel validation failed for row {i}: {e}\")\n",
    "\n",
    "                try:\n",
    "                    h = HotelModel(**row).model_dump(exclude_none=True)\n",
    "                    h and hotels.append(h)\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "                try:\n",
    "                    p = PaymentModel(**row).model_dump(exclude_none=True)\n",
    "                    p and payments.append(p)\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "            except Exception as e:\n",
    "                logger.exception(f\"Unexpected error validating row {i}: {e}\")\n",
    "\n",
    "        def df_from_list(lst):\n",
    "            return pd.DataFrame(lst) if len(lst) else pd.DataFrame()\n",
    "\n",
    "        users_df = df_from_list(users)\n",
    "        sessions_df = df_from_list(sessions)\n",
    "        events_df = df_from_list(events)\n",
    "        hotels_df = df_from_list(hotels)\n",
    "        payments_df = df_from_list(payments)\n",
    "\n",
    "        # dedupe where appropriate\n",
    "        if not users_df.empty and 'user_id' in users_df.columns:\n",
    "            users_df = users_df.drop_duplicates(subset=['user_id'])\n",
    "        if not sessions_df.empty and 'session_id' in sessions_df.columns:\n",
    "            sessions_df = sessions_df.drop_duplicates(subset=['session_id'])\n",
    "        if not hotels_df.empty and 'hotel_id' in hotels_df.columns:\n",
    "            hotels_df = hotels_df.drop_duplicates(subset=['hotel_id'])\n",
    "\n",
    "        return {\n",
    "            'users': users_df,\n",
    "            'sessions': sessions_df,\n",
    "            'events': events_df,\n",
    "            'hotels': hotels_df,\n",
    "            'payments': payments_df\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b484815c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------- Data Quality ---------------------------\n",
    "class DataQuality:\n",
    "    @staticmethod\n",
    "    def null_check(df: pd.DataFrame, cols: list):\n",
    "        missing = {c: int(df[c].isna().sum()) for c in cols if c in df.columns}\n",
    "        total = len(df)\n",
    "        for c, m in missing.items():\n",
    "            if m > 0:\n",
    "                logger.error(f\"DQ Failed: {m}/{total} nulls in column {c}\")\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    @staticmethod\n",
    "    def duplicate_check(df: pd.DataFrame, key_cols: list):\n",
    "        if not set(key_cols).issubset(set(df.columns)):\n",
    "            logger.warning(\"duplicate_check: key cols not in dataframe\")\n",
    "            return True\n",
    "        dup = df.duplicated(subset=key_cols).sum()\n",
    "        if dup > 0:\n",
    "            logger.error(f\"DQ Failed: {dup} duplicate rows for keys {key_cols}\")\n",
    "            return False\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "423ca5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------- Writer ---------------------------\n",
    "class MySQLWriter:\n",
    "    def __init__(self, config_path: str):\n",
    "\n",
    "        p = Path(config_path)\n",
    "        text = p.read_text(encoding=\"utf-8\")\n",
    "        data = json.loads(text)\n",
    "\n",
    "        kullanici = data[\"kullanici\"]\n",
    "        sifre = data[\"sifre\"]\n",
    "        host = data[\"host\"]\n",
    "        port = data[\"port\"]\n",
    "        veritabani = data[\"veritabani\"]\n",
    "\n",
    "        conn_str = f\"mysql+pymysql://{kullanici}:{sifre}@{host}:{port}/{veritabani}?charset=utf8mb4\"\n",
    "        self.engine = create_engine(conn_str, pool_pre_ping=True)\n",
    "        logger.info(\"MySQL bağlantısı JSON dosyasından oluşturuldu.\")\n",
    "\n",
    "    def write_table(self, df: pd.DataFrame, table_name: str, if_exists=\"append\"):\n",
    "        if df.empty:\n",
    "            logger.warning(f\"{table_name} tablosu için yazılacak veri yok.\")\n",
    "            return\n",
    "\n",
    "        df.to_sql(table_name, con=self.engine, index=False, if_exists=if_exists, method=\"multi\")\n",
    "        logger.info(f\"{len(df)} satır {table_name} tablosuna yazıldı.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35cc611e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------- PIPELINE ---------------------------------------\n",
    "class FunnelPipeline:\n",
    "    def __init__(self, data_path: str, config_path: str):\n",
    "        self.data_path = Path(data_path)\n",
    "        self.config_path = config_path\n",
    "        self.writer = MySQLWriter(config_path=config_path)\n",
    "\n",
    "    def read_data(self) -> pd.DataFrame:\n",
    "        \"\"\"Parquet veya CSV dosyasını okur\"\"\"\n",
    "        if self.data_path.suffix in [\".parquet\", \".gzip\", \".cpgz\"]:\n",
    "            df = pd.read_parquet(self.data_path)\n",
    "        else:\n",
    "            raise ValueError(\"Desteklenmeyen dosya formatı.\")\n",
    "        logger.info(f\"{len(df)} satır okundu.\")\n",
    "        return df\n",
    "\n",
    "    def process_data(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Basit örnek: null satırları temizle\"\"\"\n",
    "        before = len(df)\n",
    "        df = df.dropna(how=\"all\")\n",
    "        after = len(df)\n",
    "        logger.info(f\"Veri temizlendi: {before - after} boş satır silindi.\")\n",
    "        return df\n",
    "\n",
    "    def run(self, table_name=\"funnel_events\"):\n",
    "        df = self.read_data()\n",
    "        df = self.process_data(df)\n",
    "        self.writer.write_table(df, table_name=table_name, if_exists=\"append\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08ba0289",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-18 21:27:44,373 INFO MySQL bağlantısı JSON dosyasından oluşturuldu.\n",
      "2025-10-18 21:27:46,587 INFO 350690 satır okundu.\n",
      "2025-10-18 21:27:46,709 INFO Veri temizlendi: 0 boş satır silindi.\n",
      "2025-10-18 21:29:50,117 ERROR Pipeline execution failed: Can't reconnect until invalid transaction is rolled back.  Please rollback() fully before proceeding (Background on this error at: https://sqlalche.me/e/20/8s2b)\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------  KULLANIM ÖRNEĞİ ---------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    data_path = \"//Users//sdedeoglu//Desktop//python//case_data.parquet.gzip\"\n",
    "    config_path = \"//Users//sdedeoglu//Desktop//python//config.json\"\n",
    "\n",
    "    try:\n",
    "        pipeline = FunnelPipeline(data_path=data_path, config_path=config_path)\n",
    "        # Roll back any pending transactions before running\n",
    "        with pipeline.writer.engine.connect() as conn:\n",
    "            conn.invalidate() \n",
    "        pipeline.run(table_name=\"funnel_events\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Pipeline execution failed: {e}\")\n",
    "        # If pipeline exists, try to rollback any pending transactions\n",
    "        if 'pipeline' in locals():\n",
    "            try:\n",
    "                with pipeline.writer.engine.connect() as conn:\n",
    "                    conn.rollback()\n",
    "            except:\n",
    "                pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
