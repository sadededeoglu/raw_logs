{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b22901",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from unittest.mock import Mock, patch, MagicMock\n",
    "from log_pipeline import ParquetReader, ValidatorProcessor, UpsertWriter, LogPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf83afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_1 = pd.DataFrame({\n",
    "            'user_id': [1.0],\n",
    "            'subscriber_id': [123.0],\n",
    "            'session_id': ['session_1'],\n",
    "            'hotel_id': [101],\n",
    "            'request_id': ['req_1'],\n",
    "            'funnel_id': ['funnel_1'],\n",
    "            'timestamp': ['2024-10-19 10:00:00'],\n",
    "            'country': ['TR'],\n",
    "            'hotel_price': [100.50],\n",
    "            'currency': ['USD'], \n",
    "            'payment_status': ['success'],\n",
    "            'confirmation_number': ['CONF123'],  \n",
    "            'user_agent': ['Mozilla/5.0'],  \n",
    "            'device_type': ['desktop'],  \n",
    "            'ip_address': ['192.168.1.1'],  \n",
    "            'utm_source': ['google'],  \n",
    "            'page_name': ['search'],  \n",
    "            'search_query': ['istanbul hotel'],  \n",
    "            'destination_id': [456.0],  \n",
    "            'num_guests': [2.0],  \n",
    "            'has_email_contact_permission': [True],\n",
    "            'has_phone_contact_permission': [False]  \n",
    "        })\n",
    "\n",
    "test_data_2 = pd.DataFrame({\n",
    "            'user_id': [1.0],\n",
    "            'subscriber_id': [123.0],\n",
    "            'session_id': ['session_1'],\n",
    "            'hotel_id': [101],\n",
    "            'request_id': ['req_1'],\n",
    "            'funnel_id': ['funnel_1'],\n",
    "            'timestamp': ['invalid_date'],  # Invalid\n",
    "            'country': ['TR'],\n",
    "            'hotel_price': [100.50],\n",
    "            'currency': ['USD'],\n",
    "            'payment_status': ['success'],\n",
    "            'confirmation_number': ['CONF123'],\n",
    "            'user_agent': ['Mozilla/5.0'],\n",
    "            'device_type': ['desktop'],\n",
    "            'ip_address': ['192.168.1.1'],\n",
    "            'utm_source': ['google'],\n",
    "            'page_name': ['search'],\n",
    "            'search_query': ['istanbul hotel'],\n",
    "            'destination_id': [456.0],\n",
    "            'num_guests': [2.0],\n",
    "            'has_email_contact_permission': [True],\n",
    "            'has_phone_contact_permission': [False]\n",
    "        })\n",
    "\n",
    "test_data3 = pd.DataFrame({\n",
    "            'user_id': [1.0],\n",
    "            'session_id': ['session_1'],\n",
    "            'hotel_id': [101],\n",
    "            'request_id': ['req_1'],\n",
    "            'funnel_id': ['funnel_1'],\n",
    "            'timestamp': ['2024-10-19 10:00:00']\n",
    "        })\n",
    "        \n",
    "test_data_4 = pd.DataFrame({\n",
    "            'user_id': [1, 2],\n",
    "            'country': ['TR', 'US'],\n",
    "            'updated_Date': [datetime.now(), datetime.now()]\n",
    "        })\n",
    "\n",
    "test_data5 = pd.DataFrame({\n",
    "            'user_id': list(range(1, 2501)),  # 2500 records\n",
    "            'country': ['TR'] * 2500,\n",
    "            'updated_Date': [datetime.now()] * 2500\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e193c714",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_run_once (__main__.TestLogPipeline) ... ok\n",
      "test_read_all (__main__.TestParquetReader) ... ok\n",
      "test_read_in_batches (__main__.TestParquetReader) ... ok\n",
      "test_upsert_empty_dataframe (__main__.TestUpsertWriter) ... ok\n",
      "test_upsert_valid_dataframe (__main__.TestUpsertWriter) ... ok\n",
      "test_upsert_with_chunking (__main__.TestUpsertWriter) ... ok\n",
      "test_validate_invalid_timestamp (__main__.TestValidatorProcessor) ... ok\n",
      "test_validate_minimal_data (__main__.TestValidatorProcessor) ... ok\n",
      "test_validate_valid_data (__main__.TestValidatorProcessor) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation error: 1 validation error for EventModel\n",
      "timestamp\n",
      "  Value error, timestamp ge√ßersiz [type=value_error, input_value='invalid_date', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/value_error\n",
      "Validation error: 4 validation errors for UserModel\n",
      "subscriber_id\n",
      "  Field required [type=missing, input_value={'user_id': 1.0, 'session...: '2024-10-19 10:00:00'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/missing\n",
      "country\n",
      "  Field required [type=missing, input_value={'user_id': 1.0, 'session...: '2024-10-19 10:00:00'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/missing\n",
      "has_email_contact_permission\n",
      "  Field required [type=missing, input_value={'user_id': 1.0, 'session...: '2024-10-19 10:00:00'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/missing\n",
      "has_phone_contact_permission\n",
      "  Field required [type=missing, input_value={'user_id': 1.0, 'session...: '2024-10-19 10:00:00'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/missing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 9 tests in 0.017s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "class TestParquetReader(unittest.TestCase):\n",
    "    \n",
    "    @patch('pandas.read_parquet')\n",
    "    def test_read_all(self, mock_read_parquet):\n",
    "        # Mock data\n",
    "        mock_df = pd.DataFrame({\n",
    "            'user_id': [1, 2],\n",
    "            'session_id': ['s1', 's2'],\n",
    "            'hotel_id': [101, 102]\n",
    "        })\n",
    "        mock_read_parquet.return_value = mock_df\n",
    "        \n",
    "        reader = ParquetReader('dummy_path.parquet')\n",
    "        result = reader.read_all()\n",
    "        \n",
    "        self.assertEqual(len(result), 2)\n",
    "        mock_read_parquet.assert_called_once_with('dummy_path.parquet')\n",
    "\n",
    "    @patch('pandas.read_parquet')\n",
    "    def test_read_in_batches(self, mock_read_parquet):\n",
    "        # Mock data\n",
    "        mock_df = pd.DataFrame({\n",
    "            'user_id': [1, 2, 3, 4, 5],\n",
    "            'session_id': ['s1', 's2', 's3', 's4', 's5'],\n",
    "            'hotel_id': [101, 102, 103, 104, 105]\n",
    "        })\n",
    "        mock_read_parquet.return_value = mock_df\n",
    "        \n",
    "        reader = ParquetReader('dummy_path.parquet')\n",
    "        batches = list(reader.read_in_batches(batch_size=2))\n",
    "        \n",
    "        self.assertEqual(len(batches), 3)  # 5 records in batches of 2 = 3 batches\n",
    "        self.assertEqual(len(batches[0]), 2)\n",
    "        self.assertEqual(len(batches[1]), 2) \n",
    "        self.assertEqual(len(batches[2]), 1)\n",
    "\n",
    "class TestValidatorProcessor(unittest.TestCase):\n",
    "    \n",
    "    def setUp(self):\n",
    "        self.validator = ValidatorProcessor()\n",
    "        \n",
    "    def test_validate_valid_data(self):\n",
    "        # Valid test data \n",
    "        users, sessions, events, hotels, payments = self.validator.validate(test_data_1)\n",
    "        \n",
    "        self.assertEqual(len(users), 1)\n",
    "        self.assertEqual(len(sessions), 1)\n",
    "        self.assertEqual(len(events), 1)\n",
    "        self.assertEqual(len(hotels), 1)\n",
    "        self.assertEqual(len(payments), 1)\n",
    "        \n",
    "    def test_validate_invalid_timestamp(self):\n",
    "        # Invalid timestamp should be filtered out\n",
    "        users, sessions, events, hotels, payments = self.validator.validate(test_data_2)\n",
    "        # Should have no valid events due to invalid timestamp\n",
    "        self.assertEqual(len(events), 0)\n",
    "        # But other tables should still have data\n",
    "        self.assertEqual(len(users), 1)\n",
    "        self.assertEqual(len(sessions), 1)\n",
    "\n",
    "    def test_validate_minimal_data(self):\n",
    "        # Test with minimal required fields only\n",
    "        users, sessions, events, hotels, payments = self.validator.validate(test_data3)\n",
    "        # Should fail validation due to missing required fields\n",
    "        self.assertEqual(len(users), 0)  # Missing subscriber_id, permissions\n",
    "        self.assertEqual(len(events), 0)  # Missing some fields\n",
    "        self.assertEqual(len(sessions), 0)  # Missing some fields\n",
    "\n",
    "class TestUpsertWriter(unittest.TestCase):\n",
    "    \n",
    "    def setUp(self):\n",
    "        self.mock_engine = Mock()\n",
    "        self.writer = UpsertWriter(self.mock_engine)\n",
    "        \n",
    "    def test_upsert_empty_dataframe(self):\n",
    "        # Empty DataFrame should not execute any SQL\n",
    "        empty_df = pd.DataFrame()\n",
    "        self.writer.upsert_df(empty_df, 'users')\n",
    "        self.mock_engine.begin.assert_not_called()\n",
    "        \n",
    "    def test_upsert_valid_dataframe(self):\n",
    "        # Valid DataFrame should execute SQL\n",
    "        # Properly mock the context manager\n",
    "        mock_conn = Mock()\n",
    "        mock_context = MagicMock()\n",
    "        mock_context.__enter__.return_value = mock_conn\n",
    "        mock_context.__exit__.return_value = None\n",
    "        self.mock_engine.begin.return_value = mock_context\n",
    "        self.writer.upsert_df(test_data_4, 'users')\n",
    "        self.mock_engine.begin.assert_called_once()\n",
    "        mock_conn.execute.assert_called()\n",
    "        \n",
    "    def test_upsert_with_chunking(self):\n",
    "        # Test chunking functionality\n",
    "        # Create a DataFrame larger than chunk size\n",
    "        mock_conn = Mock()\n",
    "        mock_context = MagicMock()\n",
    "        mock_context.__enter__.return_value = mock_conn\n",
    "        mock_context.__exit__.return_value = None\n",
    "        self.mock_engine.begin.return_value = mock_context\n",
    "        self.writer.upsert_df(test_data5, 'users', chunk_size=1000)\n",
    "        # Should call execute 3 times (2500 / 1000 = 3 chunks)\n",
    "        self.assertEqual(mock_conn.execute.call_count, 3)\n",
    "\n",
    "class TestLogPipeline(unittest.TestCase):\n",
    "    \n",
    "    def setUp(self):\n",
    "        self.mock_engine = Mock()\n",
    "        \n",
    "    @patch('log_pipeline.ParquetReader')\n",
    "    @patch('log_pipeline.ValidatorProcessor')\n",
    "    @patch('log_pipeline.UpsertWriter')\n",
    "    def test_run_once(self, mock_writer_class, mock_validator_class, mock_reader_class):\n",
    "        # Setup mocks\n",
    "        mock_reader = Mock()\n",
    "        mock_validator = Mock()\n",
    "        mock_writer = Mock()\n",
    "        \n",
    "        mock_reader_class.return_value = mock_reader\n",
    "        mock_validator_class.return_value = mock_validator\n",
    "        mock_writer_class.return_value = mock_writer\n",
    "        \n",
    "        # Mock data\n",
    "        mock_df = pd.DataFrame({\n",
    "            'user_id': [1.0],\n",
    "            'session_id': ['s1'],\n",
    "            'hotel_id': [101],\n",
    "            'request_id': ['req1'],\n",
    "            'funnel_id': ['f1']\n",
    "        })\n",
    "        mock_reader.read_all.return_value = mock_df\n",
    "        \n",
    "        # Mock validator returns\n",
    "        mock_validator.validate.return_value = (\n",
    "            pd.DataFrame({'user_id': [1]}),  # users\n",
    "            pd.DataFrame({'session_id': ['s1']}),  # sessions  \n",
    "            pd.DataFrame({'request_id': ['req1']}),  # events\n",
    "            pd.DataFrame({'hotel_id': [101]}),  # hotels\n",
    "            pd.DataFrame({'request_id': ['req1']})  # payments\n",
    "        )\n",
    "        \n",
    "        # Create pipeline and run\n",
    "        pipeline = LogPipeline('dummy_path.parquet', self.mock_engine)\n",
    "        pipeline.run_once()\n",
    "        \n",
    "        # Verify calls\n",
    "        mock_reader.read_all.assert_called_once()\n",
    "        mock_validator.validate.assert_called_once()\n",
    "        self.assertEqual(mock_writer.upsert_df.call_count, 5)  # 5 tables\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Test runner\n",
    "    unittest.main(argv=[''], exit=False, verbosity=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
